{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legal-recorder",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-pension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:27.135969Z",
     "start_time": "2021-05-11T16:05:18.553Z"
    }
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.0.1`\n",
    "import $ivy.`org.apache.spark::spark-mllib:3.0.1`\n",
    "import $ivy.`org.plotly-scala::plotly-almond:0.7.6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-drill",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:28.421302Z",
     "start_time": "2021-05-11T16:05:20.658Z"
    }
   },
   "outputs": [],
   "source": [
    "val currentDirectory = new java.io.File(\".\").getCanonicalPath\n",
    "val path = java.nio.file.FileSystems.getDefault().getPath(s\"$currentDirectory/lib/TDM-assembly-0.3.0.jar\")\n",
    "val x = ammonite.ops.Path(path)\n",
    "interp.load.cp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-recycling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:29.351486Z",
     "start_time": "2021-05-11T16:05:21.434Z"
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SaveMode, SparkSession}\n",
    "import org.apache.spark.sql.functions._\n",
    "import tdm._\n",
    "import tdm.core._\n",
    "import tdm.core.decomposition.Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-anxiety",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:32.592062Z",
     "start_time": "2021-05-11T16:05:22.561Z"
    }
   },
   "outputs": [],
   "source": [
    "implicit val spark = {\n",
    "    SparkSession.builder()\n",
    "        .appName(\"PrimarySchoolTDM\")\n",
    "        .master(\"local[*]\")\n",
    "        .getOrCreate()\n",
    "}\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-porcelain",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-recommendation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:38.527501Z",
     "start_time": "2021-05-11T16:05:31.883Z"
    }
   },
   "outputs": [],
   "source": [
    "var df = spark.read.format(\"csv\").option(\"header\",\"false\")\n",
    "        .option(\"sep\", \"\\t\").load(\"datasets/primaryschool.csv\")\n",
    "        .toDF(\"time\", \"student1\", \"student2\", \"class1\", \"class2\")\n",
    "        .withColumn(\"time\", floor(col(\"time\") / (3600 / 12)).cast(\"integer\"))\n",
    "        .withColumn(\"student1\", floor(col(\"student1\") - 1425))\n",
    "        .withColumn(\"student2\", floor(col(\"student2\") - 1425))\n",
    "        .groupBy(\"time\", \"student1\", \"student2\", \"class1\", \"class2\").count\n",
    "        .withColumnRenamed(\"count\", \"val\")\n",
    "        .withColumn(\"val\", lit(1))\n",
    "df = df.union(\n",
    "    df.withColumnRenamed(\"student1\", \"studenttmp\")\n",
    "        .withColumnRenamed(\"student2\", \"student1\")\n",
    "        .withColumnRenamed(\"studenttmp\", \"student2\")\n",
    "        .withColumnRenamed(\"class1\", \"classtmp\")\n",
    "        .withColumnRenamed(\"class2\", \"class1\")\n",
    "        .withColumnRenamed(\"classtmp\", \"class2\")\n",
    "        .select(\"time\", \"student1\", \"student2\", \"class1\", \"class2\", \"val\")\n",
    ").dropDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-wisconsin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:39.052581Z",
     "start_time": "2021-05-11T16:05:34.434Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"student1\", concat(col(\"class1\"), lit(\"-\"), col(\"student1\")))\n",
    "        .withColumn(\"student2\", concat(col(\"class2\"), lit(\"-\"), col(\"student2\")))\n",
    "        .drop(\"class1\")\n",
    "        .drop(\"class2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-infrastructure",
   "metadata": {},
   "source": [
    "# Create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-allen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:39.535242Z",
     "start_time": "2021-05-11T16:05:37.251Z"
    }
   },
   "outputs": [],
   "source": [
    "object Student1 extends TensorDimension[String]\n",
    "object Student2 extends TensorDimension[String]\n",
    "object Time extends TensorDimension[Int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-circular",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:05:40.374861Z",
     "start_time": "2021-05-11T16:05:38.001Z"
    }
   },
   "outputs": [],
   "source": [
    "val tensor = TensorBuilder[Int](df)\n",
    "                .addDimension(Student1, \"student1\")\n",
    "                .addDimension(Student2, \"student2\")\n",
    "                .addDimension(Time, \"time\")\n",
    "                .build(\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-cancellation",
   "metadata": {},
   "source": [
    "# Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-recall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:07:14.446180Z",
     "start_time": "2021-05-11T16:05:42.667Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val kruskal = tensor.canonicalPolyadicDecomposition(13, norm = Norm.L2, computeCorcondia = true, minFms = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-stephen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:07:34.346142Z",
     "start_time": "2021-05-11T16:07:33.684Z"
    }
   },
   "outputs": [],
   "source": [
    "val student1Tensor = kruskal.extract(Student1)\n",
    "val student2Tensor = kruskal.extract(Student2)\n",
    "val timeTensor = kruskal.extract(Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-variation",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-person",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:15:44.506674Z",
     "start_time": "2021-05-11T16:15:44.082Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.Almond._\n",
    "\n",
    "init(offline=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-allocation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:14:38.494247Z",
     "start_time": "2021-05-11T16:14:37.271Z"
    }
   },
   "outputs": [],
   "source": [
    "val students = {\n",
    "    val collectedStudents = student1Tensor.projection(Rank)(0).collect\n",
    "    (for (i <- collectedStudents.indices) yield {\n",
    "        collectedStudents(Student1, i)\n",
    "    }).toList.sorted.zipWithIndex\n",
    "}\n",
    "val studentsIdToName = students.map(v => v._2 -> v._1).toMap\n",
    "val studentsNameToId = students.map(v => v._1 -> v._2).toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-importance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T16:14:58.304555Z",
     "start_time": "2021-05-11T16:14:57.824Z"
    }
   },
   "outputs": [],
   "source": [
    "def orderClasses(classesToOrder: Array[Array[Double]]): Array[Array[Double]] = {\n",
    "    val levels = List(\"1A\", \"1B\", \"2A\", \"2B\", \"3A\", \"3B\", \"4A\", \"4B\", \"5A\", \"5B\")\n",
    "    val result = Array.ofDim[Double](classesToOrder.length, classesToOrder(0).length)\n",
    "    var alreadyOrdered = List[Int]()\n",
    "    var currentIndex = classesToOrder.length - 1\n",
    "    // Put the communities that are classes\n",
    "    for (level <- levels) {\n",
    "        for (rank <- 0 until classesToOrder.length if !alreadyOrdered.contains(rank)) {\n",
    "            val sum = classesToOrder(rank).sum\n",
    "            var levelSum = 0.0\n",
    "            for (id <- classesToOrder(rank).indices) {\n",
    "                if (studentsIdToName(id).split(\"-\")(0) == level) {\n",
    "                    levelSum += classesToOrder(rank)(id)\n",
    "                }\n",
    "            }\n",
    "            if (levelSum > (sum / 2)) {\n",
    "                result(currentIndex) = classesToOrder(rank)\n",
    "                currentIndex -= 1\n",
    "                alreadyOrdered :+= rank\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    // Put the communities that are not classes\n",
    "    for (rank <- 0 until classesToOrder.length if !alreadyOrdered.contains(rank)) {\n",
    "        result(currentIndex) = classesToOrder(rank)\n",
    "        currentIndex -= 1\n",
    "        alreadyOrdered :+= rank\n",
    "    }\n",
    "    \n",
    "    result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T09:45:32.477345Z",
     "start_time": "2021-05-06T09:44:24.416Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val nbRanks = kruskal.lambdas.size\n",
    "println(nbRanks)\n",
    "val classes = Array.ofDim[Double](nbRanks, 242)\n",
    "for (rank <- 0 until nbRanks) {\n",
    "    val collectedClass1 = student1Tensor.projection(Rank)(rank).collect\n",
    "    val collectedClass2 = student2Tensor.projection(Rank)(rank).collect\n",
    "   \n",
    "    for (i <- collectedClass1.indices) {\n",
    "        classes(rank)(studentsNameToId(collectedClass1(Student1, i))) += math.abs(collectedClass1(i))\n",
    "        classes(rank)(studentsNameToId(collectedClass2(Student2, i))) += math.abs(collectedClass2(i))\n",
    "    }\n",
    "    classes(rank) = classes(rank).map(v => v / classes(rank).max)\n",
    "}\n",
    "var plot = Seq(\n",
    "        Heatmap(x = studentsNameToId.keys.toList.sorted.toSeq,\n",
    "                y = (0 until nbRanks).toSeq,\n",
    "                z = orderClasses(classes).map(_.toSeq).toSeq\n",
    "        )\n",
    ")\n",
    "plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-gnome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T11:53:22.196809Z",
     "start_time": "2021-05-11T11:52:47.297Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val nbRanks = kruskal.lambdas.size\n",
    "for (rank <- 0 until nbRanks) {\n",
    "    val studentMap = scala.collection.mutable.Map[String, Double]()\n",
    "    val student1Collected = {\n",
    "        val students = student1Tensor.projection(Rank)(rank)\n",
    "            .selection(v => math.abs(v) > 0.01).collect.orderByValuesDesc\n",
    "        for (i <- students.indices) {\n",
    "            studentMap(students(Student1, i)) = studentMap.getOrElse(students(Student1, i), 0.0) + math.abs(students(i))\n",
    "        }\n",
    "    }\n",
    "    val student2Collected = {\n",
    "        val students = student2Tensor.projection(Rank)(rank)\n",
    "            .selection(v => math.abs(v) > 0.01).collect.orderByValuesDesc\n",
    "        for (i <- students.indices) {\n",
    "            studentMap(students(Student2, i)) = studentMap.getOrElse(students(Student2, i), 0.0) + math.abs(students(i))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    val days1 = {\n",
    "            val days = timeTensor.projection(Rank)(rank)\n",
    "                .restriction(Time.condition(v => v <= (62300 / (5 * 60)))).collect\n",
    "            (for (i <- days.indices) yield {\n",
    "                (days(Time, i), days(i))\n",
    "            }).toList.sortWith((d1, d2) => d1._1 < d2._1)\n",
    "        }\n",
    "    val days2 = {\n",
    "            val days = timeTensor.projection(Rank)(rank)\n",
    "                .restriction(Time.condition(v => v >= (117240 / (5 * 60)))).collect\n",
    "            (for (i <- days.indices) yield {\n",
    "                (days(Time, i), days(i))\n",
    "            }).toList.sortWith((d1, d2) => d1._1 < d2._1)\n",
    "        }\n",
    "    \n",
    "    val nbMinutes = 5\n",
    "    var plot = Seq(\n",
    "        // Day 1\n",
    "        Bar(\n",
    "            days1.map(v => {\n",
    "                    val hours = math.floor((v._1 * nbMinutes) / 60).toInt\n",
    "                    s\"${hours}h${(v._1 * nbMinutes) - hours * 60}\"\n",
    "                }).toSeq, \n",
    "            days1.map(v => math.abs(v._2)).toSeq,\n",
    "            name = \"Day 1\",\n",
    "            xaxis = AxisReference.X1,\n",
    "            yaxis = AxisReference.Y1\n",
    "        ),\n",
    "        // Day 2\n",
    "        Bar(\n",
    "            days2.map(v => {\n",
    "                    val hours = math.floor((v._1 * nbMinutes) / 60).toInt\n",
    "                    s\"${hours - 24}h${(v._1 * nbMinutes) - hours * 60}\"\n",
    "                }).toSeq, \n",
    "            days2.map(v => math.abs(v._2)).toSeq,\n",
    "            name = \"Day 2\",\n",
    "            xaxis = AxisReference.X2,\n",
    "            yaxis = AxisReference.Y2\n",
    "        ),\n",
    "        Bar(\n",
    "            (for ((k, v) <- studentMap) yield (k, v)).toList.sortWith((e1, e2) => e1._2 > e2._2).map(v => v._1),\n",
    "            (for ((k, v) <- studentMap) yield (k, v)).toList.sortWith((e1, e2) => e1._2 > e2._2).map(v => (v._2 / 2)),\n",
    "            name = \"Students\",\n",
    "            xaxis = AxisReference.X3,\n",
    "            yaxis = AxisReference.Y3\n",
    "        )\n",
    "    )\n",
    "\n",
    "    val layout = Layout(\n",
    "        title = s\"Rank $rank\",\n",
    "        width = 1000,\n",
    "        xaxis1 = Axis(anchor = AxisAnchor.Reference(AxisReference.Y1), domain = (0.0, 0.49), automargin = true),\n",
    "        xaxis2 = Axis(anchor = AxisAnchor.Reference(AxisReference.Y2), domain = (0.51, 1.0), automargin = true),\n",
    "        xaxis3 = Axis(anchor = AxisAnchor.Reference(AxisReference.Y3), domain = (0.0, 1.0), automargin = true),\n",
    "        yaxis1 = Axis(anchor = AxisAnchor.Reference(AxisReference.X1), domain = (0.55, 1.0), automargin = true),\n",
    "        yaxis2 = Axis(anchor = AxisAnchor.Reference(AxisReference.X2), domain = (0.55, 1.0), automargin = true),\n",
    "        yaxis3 = Axis(anchor = AxisAnchor.Reference(AxisReference.X3), domain = (0.0, 0.45), automargin = true),\n",
    "        legend = Legend(y = 1.1, x = .5, yanchor = Anchor.Top, xanchor = Anchor.Center, orientation = Orientation.Horizontal)\n",
    "    )\n",
    "\n",
    "    plot.plot(layout = layout, Config(), \"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-relations",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12.8)",
   "language": "scala",
   "name": "scala2128"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
